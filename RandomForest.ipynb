{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Examples Number:  14244\n",
      "Testing Examples Number:  14669\n",
      "Encoded Feature Vector:  [4001, 4002, 4003, 4004, 4005, 4006, 4007, 4008, 4009, 4010, 4011, 4012, 4013, 4014, 4015, 4016, 4017, 4018, 4019, 4020, 4021, 4022, 4023, 4024, 4025, 4026, 4027, 4028, 4029, 4030, 4031, 4032, 4033, 4034, 4035, 4036, 4037, 4038, 4039, 4040, 4041, 4042, 4043, 4044, 4045, 4046, 4047, 4048, 4049, 4050, 4051, 4052, 4053, 4054, 4055, 4056, 4057, 4058, 4059, 4060, 4061, 4062, 4063, 4064, 4065, 4066, 4067, 4068, 4069, 4070, 4071, 4072, 4073, 4074, 4075, 4076, 4077, 4078, 4079, 4080, 4081, 4082, 4083, 4084, 4085, 4086, 4087, 4088, 4089, 4090, 4091, 4092, 4093, 4094, 4095, 4096, 4097, 4098, 4099, 4100, 4101, 4102, 4103, 4104, 4105, 4106, 4107, 4108, 4109, 4110, 4111, 4112, 4113, 4114, 4115, 4116, 4117, 4118, 4119, 4120, 4121, 4122, 4123, 4124, 4125, 4126, 4127, 4128, 4129, 4130, 4131, 4132, 4133, 4134, 4135, 4136, 4137, 4138, 4139, 4140, 4141, 4142, 4143, 4144, 4145, 4146, 4147, 4148, 4149, 4150, 4151, 4152, 4153, 4154, 4155, 4156, 4157, 4158, 4159, 4160, 4161, 4162, 4163, 4164, 4165, 4166, 4167, 4168, 4169, 4170, 4171, 4172, 4173, 4174, 4175, 4176, 4177, 4178, 4179, 4180, 4181, 4182, 4183, 4184, 4185, 4186, 4187, 4188, 4189, 4190, 4191, 4192, 4193, 4194, 4195, 4196, 4197, 4198, 4199, 4200, 4201, 4202, 4203, 4204, 4205, 4206, 4207, 4208, 4209, 4210, 4211, 4212, 4213, 4214, 4215, 4216, 4217, 4218, 4219, 4220, 4221, 4222, 4223, 4224, 4225, 4226, 4227, 4228, 4229, 4230, 4231, 4232, 4233, 4234, 4235, 4236, 4237, 4238, 4239, 4240, 4241, 4242, 4243, 4244, 4245, 4246, 4247, 4248, 4249, 4250, 4251, 4252, 4253, 4254, 4255, 4256, 4257, 4258, 4259, 4260, 4261, 4262, 4263, 4264, 4265, 4266, 4267, 4268, 4269, 4270, 4271, 4272, 4273, 4274, 4275, 4276, 4277, 4278, 4279, 4280, 4281, 4282, 4283, 4284, 4285, 4286, 4287, 4288, 4289, 4290, 4291, 4292, 4293, 4294, 4295, 4296, 4297, 4298, 4299, 4300]\n",
      "Showing the first  14669  expected answers:\n",
      "[0 0 1 ... 0 0 0]\n",
      "Showing the first  14669  predicted answers:\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "Percentage of error is:  0.5056922762287818\n"
     ]
    }
   ],
   "source": [
    "from id3 import *\n",
    "from imdbDataSet import *\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "\n",
    "#Ορισμός υπερπαραμέτρων\n",
    "sys.setrecursionlimit(3000)\n",
    "\n",
    "train_n = 25000\n",
    "test_n = 25000\n",
    "tree_number = 15\n",
    "fv_skip_top = 4000\n",
    "fv_length = 300\n",
    "tree_fv_length = 75\n",
    "\n",
    "#obtain imdb data \n",
    "imdb = IMDB()\n",
    "(x_train_raw, y_train), (x_test_raw, y_test) = imdb.getTrainingData(skip_top=fv_skip_top, num_words=fv_length)\n",
    "\n",
    "#use train_n amount of training exampl\n",
    "x_train = x_train_raw[:train_n]\n",
    "print(\"Training Examples Number: \", str(len(x_train)))\n",
    "y_train = y_train[:train_n]\n",
    "\n",
    "\n",
    "#use test_n amount of testing examples\n",
    "x_test = x_test_raw[:test_n]\n",
    "print(\"Testing Examples Number: \", str(len(x_test)))\n",
    "y_test = y_test[:test_n]\n",
    "\n",
    "\n",
    "#create encoded feature vector (index of words)\n",
    "encoded_feature_vector = imdb.getFeatureVector(skip_top=fv_skip_top, num_words=fv_length)\n",
    "print(\"Encoded Feature Vector: \", encoded_feature_vector)\n",
    "\n",
    "#each tree has a feature vector smaller than the original\n",
    "#choose each attribute at random\n",
    "encoded_tree_feature_vectors = []\n",
    "for i in range(tree_number):\n",
    "    encoded_tree_feature_vectors.append(random.sample(encoded_feature_vector, tree_fv_length))\n",
    "\n",
    "\n",
    "#create 0-1 feature vector for each training example\n",
    "train_examples = np.zeros_like(x_train)\n",
    "for i in range(len(x_train)):\n",
    "    example = np.zeros(len(encoded_feature_vector))\n",
    "    for w in x_train[i]:  \n",
    "        if(w in encoded_feature_vector):\n",
    "            example[encoded_feature_vector.index(w)] = 1\n",
    "    train_examples[i] = example\n",
    "\n",
    "#reshape train examples to 2D array\n",
    "train_examples = np.stack(train_examples)\n",
    "\n",
    "\n",
    "#create 0-1 feature vector for each test example\n",
    "test_examples = np.zeros_like(x_test)\n",
    "for i in range(len(x_test)):\n",
    "    example = np.zeros(len(encoded_feature_vector))\n",
    "    for w in x_test[i]:  \n",
    "        if(w in encoded_feature_vector):\n",
    "            example[encoded_feature_vector.index(w)] = 1\n",
    "    test_examples[i] = example\n",
    "#reshape test examples to 2D array\n",
    "test_examples = np.stack(test_examples)\n",
    "\n",
    "\n",
    "#create ID3 forest for the ensamble\n",
    "forest = []\n",
    "for i in range(tree_number):\n",
    "    id3_tree = ID3(features=encoded_tree_feature_vectors[i])\n",
    "    id3_tree.fit(np.array(train_examples), np.array(y_train))\n",
    "    forest.append(id3_tree)\n",
    "\n",
    "\n",
    "#collect test example predictions from the forest\n",
    "all_tree_predictions = np.zeros((tree_number, len(y_test)))\n",
    "for i in range(tree_number):\n",
    "    all_tree_predictions[i] = forest[i].predict(test_examples)\n",
    "\n",
    "#organize each tree's prediction to be calculated\n",
    "tree_votes = np.zeros(len(y_test))\n",
    "for i in range(len(y_test)):\n",
    "    for j in range(len(forest)):\n",
    "        tree_votes[i] += all_tree_predictions[j][i]\n",
    "\n",
    "\n",
    "\n",
    "#implement majority vote for each example\n",
    "majority_outcome = np.zeros(len(test_examples))\n",
    "for i in range(len(all_tree_predictions)):\n",
    "    #majority predicted positive outcome (1)\n",
    "    if(tree_votes[i] / (len(forest)* 1.0) > 0.5):\n",
    "        majority_outcome[i] = 1\n",
    "\n",
    "    #majority predicted negative outcome (0)\n",
    "    elif(tree_votes[i] / (len(forest)* 1.0) < 0.5):\n",
    "        majority_outcome[i] = 0\n",
    "\n",
    "    #majority does not exists, both outcomes equally predicted -> choose randomly 0 or 1\n",
    "    else:\n",
    "        majority_outcome[i] = random.randint(0,1)\n",
    "\n",
    "#calculate errors vector\n",
    "#for each example we use 0 if the predection is correct, 1 if the prediction is erroneous\n",
    "errors = np.zeros(len(x_test))\n",
    "for i in range(len(x_test)):\n",
    "    #absolute value defines the distance of two numbers, if the distance is not 0 then \n",
    "    #the prediction is different than the actual value of y_test, therefor an error\n",
    "    errors[i] = abs(y_test[i] - majority_outcome[i]) \n",
    "\n",
    "#show results for the first n test examples\n",
    "n = len(x_test)\n",
    "print(\"Showing the first \", n, \" expected answers:\")\n",
    "print(y_test[:n])\n",
    "print(\"Showing the first \", n, \" predicted answers:\")\n",
    "print(majority_outcome[:n])\n",
    "\n",
    "#show error as percentage \n",
    "print(\"Percentage of error is: \", sum(errors)/(len(errors)*1.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
