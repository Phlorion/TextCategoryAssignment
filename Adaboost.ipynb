{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d6f85c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import random\n",
    "from imdbDataSet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f8641eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, checking_feature=None, is_leaf=False, feature_value=None, category=None):\n",
    "        self.checking_feature = checking_feature\n",
    "        self.feature_value = feature_value\n",
    "        self.is_leaf = is_leaf\n",
    "        self.category = category\n",
    "        self.left_child = None\n",
    "        self.right_child = None\n",
    "        # keep track of how many of the checking factor have a result of yes / no\n",
    "        self.trues = 0\n",
    "        self.falses = 0\n",
    "        self.total = 0\n",
    "        \n",
    "    def addTrue(self):\n",
    "        self.trues += 1\n",
    "        self.total += 1\n",
    "        \n",
    "    def addFalse(self):\n",
    "        self.falses += 1\n",
    "        self.total += 1\n",
    "    \n",
    "class Stump:\n",
    "    def __init__(self, root=None, left_child=None, right_child=None):\n",
    "        self.root = root\n",
    "        self.left_child = left_child\n",
    "        self.right_child = right_child\n",
    "        self.checking_feature = root.checking_feature\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f0ddf25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>...</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Sample weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    21   22   23   24   25   26   27   28   29   30  ...   63   64   65   66  \\\n",
       "0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  1.0  1.0  1.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "5  0.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "6  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "7  1.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "8  0.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  ...  0.0  0.0  0.0  0.0   \n",
       "9  1.0  0.0  1.0  1.0  1.0  1.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    67   68   69   70  Positive  Sample weights  \n",
       "0  0.0  0.0  0.0  0.0         0             0.1  \n",
       "1  0.0  0.0  0.0  0.0         0             0.1  \n",
       "2  0.0  0.0  0.0  0.0         0             0.1  \n",
       "3  0.0  0.0  0.0  0.0         0             0.1  \n",
       "4  0.0  0.0  0.0  0.0         1             0.1  \n",
       "5  0.0  0.0  0.0  0.0         0             0.1  \n",
       "6  0.0  0.0  0.0  0.0         0             0.1  \n",
       "7  0.0  0.0  0.0  0.0         0             0.1  \n",
       "8  0.0  0.0  0.0  0.0         0             0.1  \n",
       "9  0.0  0.0  0.0  0.0         0             0.1  \n",
       "\n",
       "[10 rows x 52 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def createDF(x, y, sample_w, features):\n",
    "    # make dataframe\n",
    "    df = pd.DataFrame(x, columns=features)\n",
    "    # add y column\n",
    "    features.append(\"Positive\")\n",
    "    df[\"Positive\"] = y\n",
    "    # add first sample weights to dataframe\n",
    "    features.append(\"Sample Weight\")\n",
    "    df[\"Sample weights\"] = sample_w\n",
    "    \n",
    "    return df, x, y\n",
    "\n",
    "# initialize list of lists\n",
    "imdb = IMDB()\n",
    "imdb.getTrainingData(1, 2, 3, 20, 50, 200)\n",
    "\n",
    "# get feature vector\n",
    "features = imdb.getFeatureVector(20, 50)\n",
    "\n",
    "# get values of each feature for n movie reviews\n",
    "n = 10\n",
    "x_train = np.zeros((n, len(features)))\n",
    "y_train = list()\n",
    "# for the first n reviews\n",
    "for i in range(n):\n",
    "    x_i = imdb.getXtrain(i)\n",
    "    y_train.append(imdb.getYtrain(i))\n",
    "    # for word index in x_train\n",
    "    for wi in x_i:\n",
    "        if wi == 2:\n",
    "            continue\n",
    "        elif (wi in features):\n",
    "            j = features.index(wi)\n",
    "            x_train[i][j] = 1\n",
    "\n",
    "# Create the pandas DataFrame\n",
    "sample_w = [1/n for i in range(n)]\n",
    "df = createDF(x_train, y_train, sample_w, features)[0]\n",
    "\n",
    "stumps=[]\n",
    "igs=[]\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fb311deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, but)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 4 \tN: 1 \tT: 5\n",
      "Positive \n",
      " Y: 0 \tN: 5 \tT: 5\n",
      "\n",
      "(22, film)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 4 \tN: 0 \tT: 4\n",
      "Positive \n",
      " Y: 1 \tN: 5 \tT: 6\n",
      "\n",
      "(23, on)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 5 \tN: 0 \tT: 5\n",
      "Positive \n",
      " Y: 1 \tN: 4 \tT: 5\n",
      "\n",
      "(24, not)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 6 \tN: 1 \tT: 7\n",
      "Positive \n",
      " Y: 0 \tN: 3 \tT: 3\n",
      "\n",
      "(25, you)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 5 \tN: 1 \tT: 6\n",
      "Positive \n",
      " Y: 0 \tN: 4 \tT: 4\n",
      "\n",
      "(26, are)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 6 \tN: 0 \tT: 6\n",
      "Positive \n",
      " Y: 1 \tN: 3 \tT: 4\n",
      "\n",
      "(27, his)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 9 \tN: 1 \tT: 10\n",
      "Positive \n",
      " Y: 0 \tN: 0 \tT: 0\n",
      "\n",
      "(28, have)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 2 \tN: 1 \tT: 3\n",
      "Positive \n",
      " Y: 0 \tN: 7 \tT: 7\n",
      "\n",
      "(29, he)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 8 \tN: 1 \tT: 9\n",
      "Positive \n",
      " Y: 0 \tN: 1 \tT: 1\n",
      "\n",
      "(30, be)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 6 \tN: 1 \tT: 7\n",
      "Positive \n",
      " Y: 0 \tN: 3 \tT: 3\n",
      "\n",
      "(31, one)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 7 \tN: 1 \tT: 8\n",
      "Positive \n",
      " Y: 0 \tN: 2 \tT: 2\n",
      "\n",
      "(32, all)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 4 \tN: 1 \tT: 5\n",
      "Positive \n",
      " Y: 0 \tN: 5 \tT: 5\n",
      "\n",
      "(33, at)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 4 \tN: 1 \tT: 5\n",
      "Positive \n",
      " Y: 0 \tN: 5 \tT: 5\n",
      "\n",
      "(34, by)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 8 \tN: 1 \tT: 9\n",
      "Positive \n",
      " Y: 0 \tN: 1 \tT: 1\n",
      "\n",
      "(35, an)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 5 \tN: 1 \tT: 6\n",
      "Positive \n",
      " Y: 0 \tN: 4 \tT: 4\n",
      "\n",
      "(36, they)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 6 \tN: 0 \tT: 6\n",
      "Positive \n",
      " Y: 1 \tN: 3 \tT: 4\n",
      "\n",
      "(37, who)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 8 \tN: 0 \tT: 8\n",
      "Positive \n",
      " Y: 1 \tN: 1 \tT: 2\n",
      "\n",
      "(38, so)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 6 \tN: 1 \tT: 7\n",
      "Positive \n",
      " Y: 0 \tN: 3 \tT: 3\n",
      "\n",
      "(39, from)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 6 \tN: 1 \tT: 7\n",
      "Positive \n",
      " Y: 0 \tN: 3 \tT: 3\n",
      "\n",
      "(40, like)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 5 \tN: 0 \tT: 5\n",
      "Positive \n",
      " Y: 1 \tN: 4 \tT: 5\n",
      "\n",
      "(41, her)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 9 \tN: 1 \tT: 10\n",
      "Positive \n",
      " Y: 0 \tN: 0 \tT: 0\n",
      "\n",
      "(42, or)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 7 \tN: 1 \tT: 8\n",
      "Positive \n",
      " Y: 0 \tN: 2 \tT: 2\n",
      "\n",
      "(43, just)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 3 \tN: 1 \tT: 4\n",
      "Positive \n",
      " Y: 0 \tN: 6 \tT: 6\n",
      "\n",
      "(44, about)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 8 \tN: 0 \tT: 8\n",
      "Positive \n",
      " Y: 1 \tN: 1 \tT: 2\n",
      "\n",
      "(45, it's)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 5 \tN: 1 \tT: 6\n",
      "Positive \n",
      " Y: 0 \tN: 4 \tT: 4\n",
      "\n",
      "(46, out)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 5 \tN: 1 \tT: 6\n",
      "Positive \n",
      " Y: 0 \tN: 4 \tT: 4\n",
      "\n",
      "(47, has)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 7 \tN: 0 \tT: 7\n",
      "Positive \n",
      " Y: 1 \tN: 2 \tT: 3\n",
      "\n",
      "(48, if)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 7 \tN: 1 \tT: 8\n",
      "Positive \n",
      " Y: 0 \tN: 2 \tT: 2\n",
      "\n",
      "(49, some)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 6 \tN: 1 \tT: 7\n",
      "Positive \n",
      " Y: 0 \tN: 3 \tT: 3\n",
      "\n",
      "(50, there)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 9 \tN: 1 \tT: 10\n",
      "Positive \n",
      " Y: 0 \tN: 0 \tT: 0\n",
      "\n",
      "(51, what)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 9 \tN: 1 \tT: 10\n",
      "Positive \n",
      " Y: 0 \tN: 0 \tT: 0\n",
      "\n",
      "(52, good)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 9 \tN: 1 \tT: 10\n",
      "Positive \n",
      " Y: 0 \tN: 0 \tT: 0\n",
      "\n",
      "(53, more)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 9 \tN: 1 \tT: 10\n",
      "Positive \n",
      " Y: 0 \tN: 0 \tT: 0\n",
      "\n",
      "(54, when)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 9 \tN: 1 \tT: 10\n",
      "Positive \n",
      " Y: 0 \tN: 0 \tT: 0\n",
      "\n",
      "(55, very)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 9 \tN: 1 \tT: 10\n",
      "Positive \n",
      " Y: 0 \tN: 0 \tT: 0\n",
      "\n",
      "(56, up)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 9 \tN: 1 \tT: 10\n",
      "Positive \n",
      " Y: 0 \tN: 0 \tT: 0\n",
      "\n",
      "(57, no)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 9 \tN: 1 \tT: 10\n",
      "Positive \n",
      " Y: 0 \tN: 0 \tT: 0\n",
      "\n",
      "(58, time)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 9 \tN: 1 \tT: 10\n",
      "Positive \n",
      " Y: 0 \tN: 0 \tT: 0\n",
      "\n",
      "(59, she)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 9 \tN: 1 \tT: 10\n",
      "Positive \n",
      " Y: 0 \tN: 0 \tT: 0\n",
      "\n",
      "(60, even)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 9 \tN: 1 \tT: 10\n",
      "Positive \n",
      " Y: 0 \tN: 0 \tT: 0\n",
      "\n",
      "(61, my)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 9 \tN: 1 \tT: 10\n",
      "Positive \n",
      " Y: 0 \tN: 0 \tT: 0\n",
      "\n",
      "(62, would)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 9 \tN: 1 \tT: 10\n",
      "Positive \n",
      " Y: 0 \tN: 0 \tT: 0\n",
      "\n",
      "(63, which)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 9 \tN: 1 \tT: 10\n",
      "Positive \n",
      " Y: 0 \tN: 0 \tT: 0\n",
      "\n",
      "(64, only)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 9 \tN: 1 \tT: 10\n",
      "Positive \n",
      " Y: 0 \tN: 0 \tT: 0\n",
      "\n",
      "(65, story)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 9 \tN: 1 \tT: 10\n",
      "Positive \n",
      " Y: 0 \tN: 0 \tT: 0\n",
      "\n",
      "(66, really)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 9 \tN: 1 \tT: 10\n",
      "Positive \n",
      " Y: 0 \tN: 0 \tT: 0\n",
      "\n",
      "(67, see)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 9 \tN: 1 \tT: 10\n",
      "Positive \n",
      " Y: 0 \tN: 0 \tT: 0\n",
      "\n",
      "(68, their)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 9 \tN: 1 \tT: 10\n",
      "Positive \n",
      " Y: 0 \tN: 0 \tT: 0\n",
      "\n",
      "(69, had)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 9 \tN: 1 \tT: 10\n",
      "Positive \n",
      " Y: 0 \tN: 0 \tT: 0\n",
      "\n",
      "(70, can)\n",
      "---------------------\n",
      "Negative \n",
      " Y: 9 \tN: 1 \tT: 10\n",
      "Positive \n",
      " Y: 0 \tN: 0 \tT: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create stumps\n",
    "def makeStumps(x, y, features):\n",
    "    stumps = []\n",
    "\n",
    "    for j in range(len(features) - 2):\n",
    "        root, left, right = Node(features[j]), Node(features[j], True), Node(features[j], True)\n",
    "        root.left_child = left\n",
    "        root.right_child = right\n",
    "\n",
    "        for i in range(len(x)):\n",
    "            if (x[i][j] == 0):\n",
    "                if (y[i] == 0):\n",
    "                    left.addTrue()\n",
    "                else:\n",
    "                    left.addFalse()\n",
    "            else:\n",
    "                if (y[i] == 1):\n",
    "                    right.addTrue()\n",
    "                else:\n",
    "                    right.addFalse()\n",
    "        s = Stump(root, left, right)\n",
    "        stumps.append(s)\n",
    "\n",
    "    return stumps\n",
    "\n",
    "# check stumps made\n",
    "stumps = makeStumps(x_train, y_train, features)\n",
    "for stump in stumps:\n",
    "    print(\"(\" + str(stump.root.checking_feature) + \", \" + imdb.getInvertedWordIndex(stump.root.checking_feature) + \")\\n---------------------\")\n",
    "    print(\"Negative\", \"\\n Y:\", stump.left_child.trues, \"\\tN:\", stump.left_child.falses, \"\\tT:\", stump.left_child.total)\n",
    "    print(\"Positive\", \"\\n Y:\", stump.right_child.trues, \"\\tN:\", stump.right_child.falses, \"\\tT:\", stump.right_child.total)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c095f809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, but) stump\n",
      "----------------------\n",
      "IG: 0.10803154614560007 \n",
      "\n",
      "(22, film) stump\n",
      "----------------------\n",
      "IG: 0.07898214060026876 \n",
      "\n",
      "(23, on) stump\n",
      "----------------------\n",
      "IG: 0.10803154614560007 \n",
      "\n",
      "(24, not) stump\n",
      "----------------------\n",
      "IG: 0.054824648581652036 \n",
      "\n",
      "(25, you) stump\n",
      "----------------------\n",
      "IG: 0.07898214060026876 \n",
      "\n",
      "(26, are) stump\n",
      "----------------------\n",
      "IG: 0.14448434380562802 \n",
      "\n",
      "(27, his) stump\n",
      "----------------------\n",
      "IG: 0.0 \n",
      "\n",
      "(28, have) stump\n",
      "----------------------\n",
      "IG: 0.19350684337293433 \n",
      "\n",
      "(29, he) stump\n",
      "----------------------\n",
      "IG: 0.016063092291200065 \n",
      "\n",
      "(30, be) stump\n",
      "----------------------\n",
      "IG: 0.054824648581652036 \n",
      "\n",
      "(31, one) stump\n",
      "----------------------\n",
      "IG: 0.034144039029604056 \n",
      "\n",
      "(32, all) stump\n",
      "----------------------\n",
      "IG: 0.10803154614560007 \n",
      "\n",
      "(33, at) stump\n",
      "----------------------\n",
      "IG: 0.10803154614560007 \n",
      "\n",
      "(34, by) stump\n",
      "----------------------\n",
      "IG: 0.016063092291200065 \n",
      "\n",
      "(35, an) stump\n",
      "----------------------\n",
      "IG: 0.07898214060026876 \n",
      "\n",
      "(36, they) stump\n",
      "----------------------\n",
      "IG: 0.14448434380562802 \n",
      "\n",
      "(37, who) stump\n",
      "----------------------\n",
      "IG: 0.2689955935892812 \n",
      "\n",
      "(38, so) stump\n",
      "----------------------\n",
      "IG: 0.054824648581652036 \n",
      "\n",
      "(39, from) stump\n",
      "----------------------\n",
      "IG: 0.054824648581652036 \n",
      "\n",
      "(40, like) stump\n",
      "----------------------\n",
      "IG: 0.10803154614560007 \n",
      "\n",
      "(41, her) stump\n",
      "----------------------\n",
      "IG: 0.0 \n",
      "\n",
      "(42, or) stump\n",
      "----------------------\n",
      "IG: 0.034144039029604056 \n",
      "\n",
      "(43, just) stump\n",
      "----------------------\n",
      "IG: 0.14448434380562802 \n",
      "\n",
      "(44, about) stump\n",
      "----------------------\n",
      "IG: 0.2689955935892812 \n",
      "\n",
      "(45, it's) stump\n",
      "----------------------\n",
      "IG: 0.07898214060026876 \n",
      "\n",
      "(46, out) stump\n",
      "----------------------\n",
      "IG: 0.07898214060026876 \n",
      "\n",
      "(47, has) stump\n",
      "----------------------\n",
      "IG: 0.19350684337293433 \n",
      "\n",
      "(48, if) stump\n",
      "----------------------\n",
      "IG: 0.034144039029604056 \n",
      "\n",
      "(49, some) stump\n",
      "----------------------\n",
      "IG: 0.054824648581652036 \n",
      "\n",
      "(50, there) stump\n",
      "----------------------\n",
      "IG: 0.0 \n",
      "\n",
      "(51, what) stump\n",
      "----------------------\n",
      "IG: 0.0 \n",
      "\n",
      "(52, good) stump\n",
      "----------------------\n",
      "IG: 0.0 \n",
      "\n",
      "(53, more) stump\n",
      "----------------------\n",
      "IG: 0.0 \n",
      "\n",
      "(54, when) stump\n",
      "----------------------\n",
      "IG: 0.0 \n",
      "\n",
      "(55, very) stump\n",
      "----------------------\n",
      "IG: 0.0 \n",
      "\n",
      "(56, up) stump\n",
      "----------------------\n",
      "IG: 0.0 \n",
      "\n",
      "(57, no) stump\n",
      "----------------------\n",
      "IG: 0.0 \n",
      "\n",
      "(58, time) stump\n",
      "----------------------\n",
      "IG: 0.0 \n",
      "\n",
      "(59, she) stump\n",
      "----------------------\n",
      "IG: 0.0 \n",
      "\n",
      "(60, even) stump\n",
      "----------------------\n",
      "IG: 0.0 \n",
      "\n",
      "(61, my) stump\n",
      "----------------------\n",
      "IG: 0.0 \n",
      "\n",
      "(62, would) stump\n",
      "----------------------\n",
      "IG: 0.0 \n",
      "\n",
      "(63, which) stump\n",
      "----------------------\n",
      "IG: 0.0 \n",
      "\n",
      "(64, only) stump\n",
      "----------------------\n",
      "IG: 0.0 \n",
      "\n",
      "(65, story) stump\n",
      "----------------------\n",
      "IG: 0.0 \n",
      "\n",
      "(66, really) stump\n",
      "----------------------\n",
      "IG: 0.0 \n",
      "\n",
      "(67, see) stump\n",
      "----------------------\n",
      "IG: 0.0 \n",
      "\n",
      "(68, their) stump\n",
      "----------------------\n",
      "IG: 0.0 \n",
      "\n",
      "(69, had) stump\n",
      "----------------------\n",
      "IG: 0.0 \n",
      "\n",
      "(70, can) stump\n",
      "----------------------\n",
      "IG: 0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def informationGain(category_vector, feature_values):\n",
    "    category_set = set(category_vector)\n",
    "    \n",
    "    # calculate entropy\n",
    "    HC = 0\n",
    "    for c in category_set:\n",
    "        PC = category_vector.count(c) / len(category_vector) # P(C=c)\n",
    "        HC += - PC * np.log2(PC)\n",
    "    #print(\"Entropy:\", HC)\n",
    "    \n",
    "    # calculate IG(C, X)\n",
    "    feature_set = set(feature_values)\n",
    "    HC_feature = 0\n",
    "    for value in feature_set:\n",
    "        # p_feature --> P(X=x)\n",
    "        P_feature = feature_values.count(value) / len(feature_values) # count occurences of value\n",
    "        indices = [i for i in range(len(feature_values)) if feature_values[i] == value] # rows that have X=x\n",
    "        category_of_feature = [category_vector[i] for i in indices] # category of rows listed in indices above\n",
    "        for c in category_set:\n",
    "            # PC_feature --> P(C=c|X=x)\n",
    "            PC_feature = category_of_feature.count(c) / len(category_of_feature) # given X=x, count C\n",
    "            if PC_feature != 0:\n",
    "                # - P(X=x) * P(C=c|X=x) * log2(P(C=c|X=x))\n",
    "                temp_H = - P_feature * PC_feature * np.log2(PC_feature)\n",
    "                # sum for all values of C (class) and X (values of specific feature)\n",
    "                HC_feature += temp_H\n",
    "    IG = HC - HC_feature\n",
    "    return IG\n",
    "\n",
    "# check information gain\n",
    "for s in range(len(stumps)):\n",
    "    print(\"(\" + str(stumps[s].root.checking_feature) + \", \" + imdb.getInvertedWordIndex(stumps[s].root.checking_feature) + \") stump\\n----------------------\")\n",
    "    feature_values = [x_train[i][s] for i in range(len(x_train))]\n",
    "    category_vector = list(y_train)\n",
    "    ig = informationGain(category_vector, feature_values)\n",
    "    igs.append(ig)\n",
    "    print(\"IG:\", ig, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3ebf1f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choosing stump hosting feature: (37, who)\n"
     ]
    }
   ],
   "source": [
    "# find stump with the most IG\n",
    "fstump = stumps[np.where(igs == max(igs))[0][0]] # find the index of the max IG and then get the stump from the array of stumps\n",
    "                                                # by that index\n",
    "print(\"Choosing stump hosting feature: (\" + str(fstump.checking_feature) + \", \" + imdb.getInvertedWordIndex(fstump.checking_feature) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6dd6ac9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Error of 37 stump: 0.1\n",
      "Stump's Importance: 1.0986122886681098\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def amountOfSay(totalError):\n",
    "    a = 0.5 * np.log((1 - totalError) / totalError)\n",
    "    return a\n",
    "\n",
    "def plotAmountOfSay(totalError, a):\n",
    "    # plot the performance curve\n",
    "    plt.xlabel(\"Error rate\")\n",
    "    plt.ylabel(\"Alpha\")\n",
    "    # evenly sampled error rate at 0.02 intervals\n",
    "    err_rate = np.arange(0.02, 1., 0.02)\n",
    "    plt.plot(err_rate, 0.5*np.log((1 - err_rate)/err_rate), '#004883')\n",
    "    # plot our α\n",
    "    plt.plot([totalError], [a], 'go', label=\"α = \" + str(a))\n",
    "    x_0_dotted = np.arange(-2, a+0.05, 0.05)\n",
    "    y_0_dotted = np.arange(0., totalError+0.05, 0.05) if a < 2 else np.arange(0., totalError, 0.05)\n",
    "    plt.plot(np.zeros(len(x_0_dotted)) + totalError, x_0_dotted, 'g--', linewidth=0.8)\n",
    "    plt.plot(y_0_dotted, np.zeros(len(y_0_dotted)) + a, 'g--', linewidth=0.8)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# calculate totalError\n",
    "terror = (fstump.left_child.falses + fstump.right_child.falses) / (fstump.left_child.total + fstump.right_child.total)\n",
    "# check if total error is either 0 or 1, if it is add / subtract sys.epsilon so the amount of say equation doesn't freak out\n",
    "if (terror == 0):\n",
    "    terror += sys.float_info.epsilon\n",
    "elif (terror == 1):\n",
    "    terror -= sys.float_info.epsilon\n",
    "print(\"Total Error of \" + str(fstump.checking_feature) + \" stump:\", terror)\n",
    "# find performance of stump (amount of say: α)\n",
    "a = amountOfSay(terror)\n",
    "print(\"Stump's Importance:\", a)\n",
    "# plot the amount of say\n",
    "plotAmountOfSay(terror, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6eb67e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Sample Weights: [0.03333333333333333, 0.30000000000000004, 0.03333333333333333, 0.30000000000000004, 0.03333333333333333, 0.30000000000000004, 0.03333333333333333, 0.03333333333333333, 0.03333333333333333, 0.30000000000000004]\n",
      "New Normalized Sample Weights: [0.023809523809523805, 0.21428571428571427, 0.023809523809523805, 0.21428571428571427, 0.023809523809523805, 0.21428571428571427, 0.023809523809523805, 0.023809523809523805, 0.023809523809523805, 0.21428571428571427]\n",
      "Buckets: [0.023809523809523805, 0.23809523809523808, 0.26190476190476186, 0.47619047619047616, 0.49999999999999994, 0.7142857142857142, 0.738095238095238, 0.7619047619047619, 0.7857142857142857, 1.0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>...</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Sample weights</th>\n",
       "      <th>New sample weights</th>\n",
       "      <th>Buckets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.023810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.261905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.738095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    21   22   23   24   25   26   27   28   29   30  ...   65   66   67   68  \\\n",
       "0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  1.0  1.0  1.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "5  0.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "6  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "7  1.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "8  0.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  ...  0.0  0.0  0.0  0.0   \n",
       "9  1.0  0.0  1.0  1.0  1.0  1.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    69   70  Positive  Sample weights  New sample weights   Buckets  \n",
       "0  0.0  0.0         0             0.1            0.023810  0.023810  \n",
       "1  0.0  0.0         0             0.1            0.214286  0.238095  \n",
       "2  0.0  0.0         0             0.1            0.023810  0.261905  \n",
       "3  0.0  0.0         0             0.1            0.214286  0.476190  \n",
       "4  0.0  0.0         1             0.1            0.023810  0.500000  \n",
       "5  0.0  0.0         0             0.1            0.214286  0.714286  \n",
       "6  0.0  0.0         0             0.1            0.023810  0.738095  \n",
       "7  0.0  0.0         0             0.1            0.023810  0.761905  \n",
       "8  0.0  0.0         0             0.1            0.023810  0.785714  \n",
       "9  0.0  0.0         0             0.1            0.214286  1.000000  \n",
       "\n",
       "[10 rows x 54 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def newSampleWeights(x, y, sample_w, features, stump, a):\n",
    "    new_sample_weights = []\n",
    "    # get index of checking feature and category\n",
    "    feature_j = features.index(stump.checking_feature)\n",
    "    category_j = features.index(features[len(features) - 2])\n",
    "\n",
    "    # get each row and check if it is wrongly classified based on the feature\n",
    "    for i in range(len(x)):\n",
    "        n_sample = 0\n",
    "        # left child\n",
    "        if (x[i][j] == 0):\n",
    "            # correctly classified\n",
    "            if (y[i] == 0):\n",
    "                n_sample = sample_w[i] * np.exp(-a)\n",
    "            # wrongly classified\n",
    "            else:\n",
    "                n_sample = sample_w[i] * np.exp(a)\n",
    "        # right child\n",
    "        else:\n",
    "            # correctly classified\n",
    "            if (y[i] == 1):\n",
    "                n_sample = sample_w[i] * np.exp(-a)\n",
    "            # wrongly classified\n",
    "            else:\n",
    "                n_sample = sample_w[i] * np.exp(a)\n",
    "        new_sample_weights.append(n_sample)\n",
    "        \n",
    "    return new_sample_weights\n",
    "\n",
    "def normalizeSampleWeights(sample_weights):\n",
    "    sample_sum = sum(sample_weights)\n",
    "    for i in range(len(sample_weights)):\n",
    "        sample_weights[i] = sample_weights[i] / sample_sum\n",
    "\n",
    "def makeBuckets(sample_weight):\n",
    "    buckets = []\n",
    "    buckets.append(sample_weight[0])\n",
    "    for i in range(1, len(sample_weight), 1):\n",
    "        buckets.append(buckets[i-1] + sample_weight[i])\n",
    "    return buckets\n",
    "        \n",
    "# make new sample weights based on the right/wrong classifications\n",
    "new_sample_weights = newSampleWeights(x_train, y_train, sample_w, features, fstump, a)\n",
    "print(\"New Sample Weights:\", new_sample_weights)\n",
    "# normalize new sample weights\n",
    "normalizeSampleWeights(new_sample_weights)\n",
    "print(\"New Normalized Sample Weights:\", new_sample_weights)\n",
    "# make buckets\n",
    "buckets = makeBuckets(new_sample_weights)\n",
    "print(\"Buckets:\", buckets)\n",
    "\n",
    "# make deep copy of the dataframe\n",
    "temp_df = df.copy(True)\n",
    "\n",
    "temp_df[\"New sample weights\"] = new_sample_weights\n",
    "temp_df[\"Buckets\"] = buckets\n",
    "display(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "639ecc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>...</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Sample weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    21   22   23   24   25   26   27   28   29   30  ...   63   64   65   66  \\\n",
       "0  1.0  0.0  1.0  1.0  1.0  1.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  1.0  0.0  1.0  1.0  1.0  1.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "5  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  0.0  0.0  0.0  0.0   \n",
       "6  0.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "7  1.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "8  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  0.0  0.0  0.0  0.0   \n",
       "9  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    67   68   69   70  Positive  Sample weights  \n",
       "0  0.0  0.0  0.0  0.0         0             0.1  \n",
       "1  0.0  0.0  0.0  0.0         0             0.1  \n",
       "2  0.0  0.0  0.0  0.0         0             0.1  \n",
       "3  0.0  0.0  0.0  0.0         0             0.1  \n",
       "4  0.0  0.0  0.0  0.0         0             0.1  \n",
       "5  0.0  0.0  0.0  0.0         0             0.1  \n",
       "6  0.0  0.0  0.0  0.0         0             0.1  \n",
       "7  0.0  0.0  0.0  0.0         0             0.1  \n",
       "8  0.0  0.0  0.0  0.0         0             0.1  \n",
       "9  0.0  0.0  0.0  0.0         0             0.1  \n",
       "\n",
       "[10 rows x 52 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rigged_rand = [0.38, 0.26, 0.98, 0.40, 0.55, 0.1, 0.22, 0.35, 0.68, 0.15] # Rigged random numbers (debugging)\n",
    "\n",
    "def makeNewDF(template, x, y, features, rows):\n",
    "    new_x = []\n",
    "    new_y = []\n",
    "    new_sample_w = [1/rows for i in range(rows)]\n",
    "    features = features[:len(features)-2:1]\n",
    "    # for each row in the new data set\n",
    "    for i in range(rows):\n",
    "        rand_num = random.uniform(0, 1)\n",
    "        #print(rand_num)\n",
    "        # choose a row from the old data set\n",
    "        for j in range(rows):\n",
    "            if (rand_num < template[\"Buckets\"][j]):\n",
    "                new_x.append(x[j])\n",
    "                new_y.append(y[j])\n",
    "                break\n",
    "                \n",
    "    return createDF(new_x, new_y, new_sample_w, features)\n",
    "            \n",
    "# make new data frame with the size of the original\n",
    "# we each row we will generate a random number and having the \"Buckets\" columns as a distribution, wherever the\n",
    "# radnom number falls in the \"Buckets\" column we will take that row and add it to the new data frame\n",
    "result = makeNewDF(temp_df, x_train, y_train, features, len(y_train))\n",
    "new_df = result[0]\n",
    "new_x_train, new_y_train = result[1], result[2]\n",
    "display(new_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "50a7b6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaboost:\n",
    "    def __init__(self, iterations=5, _print=True):\n",
    "        self.iterations = iterations\n",
    "        self._print = _print # print process (yes / no)\n",
    "        self.x_train = None\n",
    "        self.y_train = None\n",
    "        self.sample_w = None\n",
    "        self.features = None\n",
    "        self.df = None\n",
    "        self.dfs = []\n",
    "        self.chosen_stump = None\n",
    "        self.chosen_stumps = []\n",
    "        self.chosen_stump_a = None\n",
    "        self.chosen_stumps_a = []\n",
    "        \n",
    "    def fit(self, x, y, features):\n",
    "        self.x_train = x\n",
    "        self.y_train = y\n",
    "        n = len(y_train)\n",
    "        self.sample_w = [1/n for i in range(n)]\n",
    "        self.features = features\n",
    "        self.df = createDF(self.x_train, self.y_train, self.sample_w, self.features)[0]\n",
    "        for i in range(self.iterations):\n",
    "            if (self._print):\n",
    "                display(self.df)\n",
    "            self.train()\n",
    "            if (self._print):\n",
    "                print(10*\"----------\")\n",
    "        \n",
    "    def train(self):\n",
    "        # make stumps and get IG of each stump\n",
    "        _stumps = makeStumps(self.x_train, self.y_train, self.features)\n",
    "        _igs = []\n",
    "        for s in range(len(_stumps)):\n",
    "            if (self._print):\n",
    "                print(\"(\" + str(_stumps[s].root.checking_feature) + \", \" + imdb.getInvertedWordIndex(_stumps[s].root.checking_feature) + \")\\n---------------------\")\n",
    "                print(\"Negative\", \"\\n Y:\", _stumps[s].left_child.trues, \"\\tN:\", _stumps[s].left_child.falses, \"\\tT:\", _stumps[s].left_child.total)\n",
    "                print(\"Positive\", \"\\n Y:\", _stumps[s].right_child.trues, \"\\tN:\", _stumps[s].right_child.falses, \"\\tT:\", _stumps[s].right_child.total)\n",
    "                print()\n",
    "                \n",
    "                print(\"(\" + str(_stumps[s].root.checking_feature) + \", \" + imdb.getInvertedWordIndex(_stumps[s].root.checking_feature) + \") stump\\n----------------------\")\n",
    "            feature_values = [self.x_train[i][s] for i in range(len(self.x_train))]\n",
    "            category_vector = list(self.y_train)\n",
    "            ig = informationGain(category_vector, feature_values)\n",
    "            _igs.append(ig)\n",
    "            if (self._print):\n",
    "                print(\"IG:\", ig, \"\\n\")\n",
    "        \n",
    "        # find stump with the most IG\n",
    "        self.chosen_stump = _stumps[np.where(_igs == max(_igs))[0][0]] # find the index of the max IG and then get the stump from the array of stumps\n",
    "                                                                    # by that index\n",
    "        if (self._print):\n",
    "            print(\"Choosing stump hosting feature: (\" + str(self.chosen_stump.checking_feature) + \", \" + imdb.getInvertedWordIndex(self.chosen_stump.checking_feature) + \")\")\n",
    "        self.chosen_stumps.append(self.chosen_stump)\n",
    "        \n",
    "        # calculate totalError\n",
    "        _terror = (self.chosen_stump.left_child.falses + self.chosen_stump.right_child.falses) / (self.chosen_stump.left_child.total + self.chosen_stump.right_child.total)\n",
    "        # check if total error is either 0 or 1, if it is add / subtract sys.epsilon so the amount of say equation doesn't freak out\n",
    "        if (_terror == 0):\n",
    "            _terror += sys.float_info.epsilon\n",
    "        elif (_terror == 1):\n",
    "            _terror -= sys.float_info.epsilon\n",
    "\n",
    "        # find performance of stump (amount of say: α)\n",
    "        self.chosen_stump_a = amountOfSay(_terror)\n",
    "        self.chosen_stumps_a.append(self.chosen_stump_a)\n",
    "\n",
    "        if (self._print):\n",
    "            print(\"Total Error of \" + str(self.chosen_stump.checking_feature) + \" stump:\", _terror)\n",
    "            print(\"Stump's Importance:\", self.chosen_stump_a)\n",
    "        \n",
    "        # make new sample weights based on the right/wrong classifications\n",
    "        _new_sample_weights = newSampleWeights(self.x_train, self.y_train, self.sample_w, self.features, self.chosen_stump, self.chosen_stump_a)\n",
    "        if (self._print):\n",
    "            print(\"New Sample Weights:\", _new_sample_weights)\n",
    "        # normalize new sample weights\n",
    "        normalizeSampleWeights(_new_sample_weights)\n",
    "        # make buckets\n",
    "        _buckets = makeBuckets(_new_sample_weights)\n",
    "        if (self._print):\n",
    "            print(\"New Normalized Sample Weights:\", _new_sample_weights)\n",
    "            print(\"Buckets:\", buckets)\n",
    "        \n",
    "        self.df[\"New sample weights\"] = _new_sample_weights\n",
    "        self.df[\"Buckets\"] = _buckets\n",
    "        if (self._print):\n",
    "            display(self.df)\n",
    "        \n",
    "        # make new data frame with the size of the original\n",
    "        # we each row we will generate a random number and having the \"Buckets\" columns as a distribution, wherever the\n",
    "        # radnom number falls in the \"Buckets\" column we will take that row and add it to the new data frame\n",
    "        self.dfs.append(self.df)\n",
    "        n = len(self.df)\n",
    "        new_data_frame = makeNewDF(self.df, self.x_train, self.y_train, self.features, n)\n",
    "        self.df, self.x_train, self.y_train = new_data_frame[0], new_data_frame[1], new_data_frame[2]\n",
    "        self.sample_w = [1/n for i in range(n)]\n",
    "\n",
    "    def predict(self, X, cap, features):\n",
    "        if (features != self.features):\n",
    "            print(\"Features of given don't match\")\n",
    "            return\n",
    "        \n",
    "        predictions = list()\n",
    "        tempX = X[:cap]\n",
    "        \n",
    "        # for every x in X\n",
    "        for x in tempX:\n",
    "            positive_votes = list()\n",
    "            negative_votes = list()\n",
    "            # for every stump in the stump forest\n",
    "            for i in range(len(self.chosen_stumps)):\n",
    "                # stump\n",
    "                stump = self.chosen_stumps[i]\n",
    "                # what are we checking in this stump\n",
    "                checking_word = stump.checking_feature\n",
    "                # check if the word exists in the given x\n",
    "                if (checking_word in x):\n",
    "                    # then go to right_child and check how many correct classifications we have in this case\n",
    "                    # correctly classified\n",
    "                    if (stump.right_child.trues >= stump.right_child.falses):\n",
    "                        positive_votes.append(self.chosen_stumps_a[i])\n",
    "                    # wrongly classified\n",
    "                    else:\n",
    "                        negative_votes.append(self.chosen_stumps_a[i])\n",
    "                # if it doesn't exist in x\n",
    "                else:\n",
    "                    # then go to left child and check how many correct classifications we have in this case\n",
    "                    # wrongly classified\n",
    "                    if (stump.left_child.falses >= stump.left_child.trues):\n",
    "                        positive_votes.append(self.chosen_stumps_a[i])\n",
    "                    # correctly classified\n",
    "                    else:\n",
    "                        negative_votes.append(self.chosen_stumps_a[i])\n",
    "            # check which has the biggest sum\n",
    "            print(sum(positive_votes), \"\\n\", sum(negative_votes))\n",
    "            # positive\n",
    "            if (sum(positive_votes) >= sum(negative_votes)):\n",
    "                predictions.append(1)\n",
    "            # negative\n",
    "            else:\n",
    "                predictions.append(0)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f17bfbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]: [START] please give this one a miss br br kristy swanson and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite lacklustre so all you madison fans give this a miss\n",
      "[1]: [START] i generally love this type of movie however this time i found myself wanting to kick the screen since i can't do that i will just complain about it this was absolutely idiotic the things that happen with the dead kids are very cool but the alive people are absolute idiots i am a grown man pretty big and i can defend myself well however i would not do half the stuff the little girl does in this movie also the mother in this movie is reckless with her children to the point of neglect i wish i wasn't so angry about her and her actions because i would have otherwise enjoyed the flick what a number she was take my advise and fast forward through everything you see her do until the end also is anyone else getting sick of watching movies that are filmed so dark anymore one can hardly see what is being filmed as an audience we are impossibly involved with the actions on the screen so then why the hell can't we have night vision\n",
      "[2]: [START] like some other people wrote i'm a die hard mario fan and i loved this game br br this game starts slightly boring but trust me it's worth it as soon as you start your hooked the levels are fun and exiting they will hook you 'till your mind turns to mush i'm not kidding this game is also orchestrated and is beautifully done br br to keep this spoiler free i have to keep my mouth shut about details but please try this game it'll be worth it br br story 9 9 action 10 1 it's that good hardness 10 attention grabber 10 average 10\n",
      "[3]: [START] i'm absolutely disgusted this movie isn't being sold all who love this movie should email disney and increase the demand for it they'd eventually have to sell it then i'd buy copies for everybody i know everything and everybody in this movie did a good job and i haven't figured out why disney hasn't put this movie on dvd or on vhs in rental stores at least i haven't seen any copies this is a wicked good movie and should be seen by all the kids in the new generation don't get to see it and i think they should it should at least be put back on the channel this movie doesn't deserve a cheap download it deserves the real thing i'm them now this movie will be on dvd\n",
      "[4]: [START] the emperor's richard [OOV] dog is betrothed to [OOV] joan fontaine dog however when virgil bing crosby arrives in town to sell a record player to the emperor his dog is attacked by [OOV] dog after a revenge attack where virgil is banished from town a psychoanalyst insists that [OOV] dog must confront dog so that she can overcome her doggy fears this is arranged and the dogs fall in love so do virgil and johanna the rest of the film passes by with romance and at the end [OOV] dog gives birth but who is the father br br the dog story is the very weak vehicle that is used to try and create a story between humans its a terrible storyline there are 3 main musical pieces all of which are rubbish bad songs and dreadful choreography its just an extremely boring film bing has too many words in each sentence and delivers them in an almost irritating manner its not funny ever but its meant to be bing and joan have done much better than this\n",
      "[5]: [START] hollywood had a long love affair with bogus arabian nights tales but few of these products have stood the test of time the most memorable were the jon hall maria montez films which have long since become camp this one is filled with dubbed songs anachronistic slang and slapstick it's a truly crop of corn and pretty near intolerable today it was nominated for its imaginative special effects which are almost unnoticeable in this day and age consisting mainly of trick photography the only outstanding positive feature which survives is its beautiful color and clarity sad to say of the many films made in this genre few of them come up to alexander korda's original thief of baghdad almost any other arabian nights film is superior to this one though it's a loser\n",
      "[6]: [START] a touching documentary that puts a human face on the tragedy of 9 11 by showing how one small community to honor two high school friends lost on that day the film interweaves the lives of chris and tom through interviews with family and friends and snippets of old photos through their reminiscences we glimpse two lives tragically cut short the film also documents how through a series of coincidences an inspirational memorial garden was brought forth through the efforts of many people both known and unknown to the two victims through the laughter and the tears and the sweat we see the power of hope and honor and love this films evokes many different emotions but the final feeling is one of admiration of the human spirit by tragedy\n",
      "[7]: [START] from 1996 first i watched this movie i feel never reach the end of my satisfaction i feel that i want to watch more and more until now my god i don't believe it was ten years ago and i can believe that i almost remember every word of the dialogues i love this movie and i love this novel absolutely perfection i love willem defoe he has a strange voice to spell the words black night and i always say it for many times never being bored i love the music of it's so much made me come into another world deep in my heart anyone can feel what i feel and anyone could make the movie like this i don't believe so thanks thanks\n",
      "[8]: [START] ed kel mitchell is a teenager who lives for his job at good burger a small but friendly neighborhood hamburger stand while his buddy dexter thompson also works there but lack ed's single minded devotion to his job he's there because he accidentally destroyed the car of his teacher mr wheat sinbad and has to raise money to pay the damages when mondo burger a mammoth fast foot chain opens across the street it looks like good burger is history until ed [OOV] a secret sauce that brings hundreds of new customers to their door however the [OOV] manager of mondo burger kurt jan is determined to get his hands on the sauce and put good burger out of business meanwhile ed and dexter must rescue otis abe vigoda the world's oldest fast food employee from the demented hills asylum and ed might just find love with monique jackson if he could take his mind off the burgers long enough to pay attention to her good burger is a comedy directed for kids decent story acting and overall a pretty harmless kids movie\n",
      "[9]: [START] i was really geared up to watch when two of best movie critics tagged this movie as a [OOV] but the movie turned out be disappointing br br you will be advised to watch this movie keeping your brains at home but you simply can't ignore the flaws and the shortcomings br br 1 the missile scene was total stupidity br br 2 katrina [OOV] and govinda pair looked awful he's 49 and she's just 24 more than double of her age 3 salman's comedy is less of acting and more of overacting br br 4 songs are good but interrupts the pace of the movie br br 5 some scenes were deliberately attempted by the movie makers to be funny and 6 poor and flawed story br br however there are few pluses 1 govinda great individual performance br br 2 some scenes are actually quite funny br br 3 [OOV] looks and acting keeps on improving with every film br br 4 rajpal yadav's don sequences though under utilized but hilarious br br so 4 good points 6 bad ones this one gets 4 10\n",
      "Actual reviews: [0 0 1 1 0 0 1 1 0 0]\n",
      "-1.4557327704779823 \n",
      " 1.8981054658931393\n",
      "-1.4557327704779823 \n",
      " 1.8981054658931393\n",
      "-1.4557327704779823 \n",
      " 1.8981054658931393\n",
      "-1.4557327704779823 \n",
      " 1.8981054658931393\n",
      "-1.4557327704779823 \n",
      " 1.8981054658931393\n",
      "-1.4557327704779823 \n",
      " 1.8981054658931393\n",
      "-1.4557327704779823 \n",
      " 1.8981054658931393\n",
      "-1.4557327704779823 \n",
      " 1.8981054658931393\n",
      "-1.0788468692897921 \n",
      " 1.5212195647049491\n",
      "-0.7625855899180369 \n",
      " 1.204958285333194\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# initialize list of lists\n",
    "imdb = IMDB()\n",
    "real = imdb.getTrainingData(1, 2, 3, 0, 60000, 200)\n",
    "# print the reviews of 10 movies\n",
    "for i in range(10):\n",
    "    print(\"[\"+str(i)+\"]:\", imdb.getDecodedSequence(real[1][0], i))\n",
    "res = imdb.getTrainingData(1, 2, 3, 500, 10000, 200)\n",
    "train, test = res[0], res[1]\n",
    "print(\"Actual reviews:\", test[1][:10])\n",
    "\n",
    "# get feature vector\n",
    "features = imdb.getFeatureVector(500, 10000)\n",
    "\n",
    "# get values of each feature for n movie reviews\n",
    "n = 100\n",
    "x_train = np.zeros((n, len(features)))\n",
    "y_train = list()\n",
    "# for the first n reviews\n",
    "for i in range(n):\n",
    "    x_i = imdb.getXtrain(i)\n",
    "    y_train.append(imdb.getYtrain(i))\n",
    "    # for word index in x_train\n",
    "    for wi in x_i:\n",
    "        if wi == 2:\n",
    "            continue\n",
    "        elif (wi in features):\n",
    "            j = features.index(wi)\n",
    "            x_train[i][j] = 1\n",
    "\n",
    "adaboost = Adaboost(iterations=10, _print=False)\n",
    "adaboost.fit(x_train, y_train, features)\n",
    "\n",
    "# test\n",
    "predictions = adaboost.predict(test[0], 10, features)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e6992f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
